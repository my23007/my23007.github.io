---
layout: post
title: Ethics in Computing in the age of Generative AI
subtitle: Summary
categories: Module 8 unit1 post
tags: [Cyber security, Essex, GenAI]
---

# Introduction

The transformative rise of generative AI since late 2022 has had profound impacts across all fields, but its influence on computer science is particularly noteworthy. This reflection explores the challenges and opportunities posed by generative AI, referencing Correa et al. (2023) and Deckard (2023), alongside other relevant literature. It discusses the legal, social, ethical, and professional implications, and proposes a framework for responsible governance of AI technologies.

# The Current Landscape of Generative AI Governance

As Correa et al. (2023) highlight, one of the central challenges in AI governance is achieving consensus on values and principles across diverse global stakeholders. While AI ethics guidelines exist in many countries, they vary widely in emphasis. For instance, the European Union’s AI Act prioritizes human rights and accountability (European Commission, 2021), whereas the United States adopts a market-driven approach with guidelines like the Blueprint for an AI Bill of Rights focusing on specific use cases (Office of Science and Technology Policy, 2022). Countries like China emphasize national security and social harmony.

These variations reflect different cultural, economic, and political priorities, making international consensus challenging. Generative AI exacerbates this complexity due to its dual-use nature. Technologies like ChatGPT and Stable Diffusion can create groundbreaking innovations while also being weaponized for disinformation, fraud, or privacy violations (Deckard, 2023). Addressing these issues requires a balance between fostering innovation and mitigating risks.

# Legal implications

Generative AI’s rapid evolution has outpaced legal frameworks in many jurisdictions. Key concerns include intellectual property (IP) rights, data protection, and liability for AI-generated outputs. For example, artists and copyright holders have raised concerns about AI models trained on copyrighted materials without consent. Courts are beginning to address these issues, but inconsistent rulings across jurisdictions complicate matters.
Moreover, privacy laws such as the General Data Protection Regulation (GDPR) challenge the use of large datasets for training generative AI models. Transparency and explainability, emphasized in GDPR’s “right to explanation,” remain difficult to implement in black-box models (Goodman and Flaxman, 2017). Establishing clear regulatory standards for training data, model accountability, and auditability is crucial to resolve these legal ambiguities.
Another legal consideration is liability. Generative AI outputs, such as deepfakes or malicious code, may cause harm to individuals or organizations. Determining who is responsible for such harm—the developers, deployers, or users—is a contentious issue. Proactively addressing these questions through regulatory frameworks will be essential to reduce ambiguity and ensure accountability.

# Social implications

Generative AI reshapes societal norms by altering how we interact with technology and each other. While it democratizes access to creative tools and enhances productivity, it also poses risks of social harm. Correa et al. (2023) emphasize the risk of amplifying biases embedded in training data, leading to discriminatory outputs. For example, biased AI-generated job descriptions can perpetuate gender or racial inequalities (Buolamwini and Gebru, 2018).
Additionally, generative AI exacerbates the spread of misinformation. Deepfakes and AI-generated text can erode trust in digital content, undermining democratic institutions and public discourse. Education and media literacy programs must be prioritized to help individuals critically evaluate AI-generated content.
The social implications extend to labor markets. Generative AI’s ability to automate creative and intellectual tasks has raised concerns about job displacement. While some roles will evolve to focus on AI oversight and integration, others may become obsolete, leading to economic and social disruptions. Policymakers and industry leaders must collaborate to support workforce reskilling and promote equitable access to AI-driven opportunities.

# Ethical implications

Ethically, generative AI raises questions about responsibility and fairness. The lack of transparency in how AI models generate outputs challenges the principle of accountability. For example, if an AI system produces harmful content, who bears responsibility—the developers, the deployers, or the users?
Correa et al. (2023) highlight the importance of inclusive governance to address these concerns. Engaging diverse stakeholders, including underrepresented groups, is essential to ensure that AI systems reflect broad societal values rather than reinforcing existing power imbalances.
The ethical principle of minimizing harm is particularly relevant. Generative AI systems should be designed to avoid negative consequences, such as perpetuating stereotypes or producing harmful outputs. Developers and organizations have an ethical obligation to ensure their models are rigorously tested and continuously monitored for unintended effects. Adopting ethical AI principles, such as those outlined by the IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems (IEEE, 2020), can guide responsible development and deployment.

# Professional implications

For computing professionals, the generative AI revolution demands a renewed focus on ethical competence and accountability. Professional bodies such as the British Computer Society (BCS) and the Association for Computing Machinery (ACM) emphasize the importance of acting in the public interest and minimizing harm (BCS, 2023; ACM, 2018). Adhering to these principles requires professionals to critically assess the societal impacts of their work and advocate for responsible AI practices.

For example, developers should prioritize embedding fairness, transparency, and explainablity into AI systems from the design phase. Continuous professional development in AI ethics and regulatory compliance is also vital to navigate the evolving landscape.
Moreover, generative AI challenges traditional notions of authorship and originality, raising questions for professionals in creative industries. Computing professionals must navigate these complexities with integrity, ensuring that AI-generated outputs respect intellectual property rights and ethical guidelines.

# Recommendations

To address the challenges posed by generative AI, the following actions are recommended:

-Global Governance Frameworks: Establishing international agreements, similar to the Paris Agreement on climate change, can provide a unified approach to AI governance. These frameworks should define minimum ethical and technical standards while allowing flexibility for local adaptation.

-Transparency and Accountability: Mandating transparency in AI model training and deployment is critical. Developers should document data sources, decision-making processes, and model limitations to enhance accountability.

-Public Engagement and Education: Governments and organizations should invest in public education campaigns to increase awareness of generative AI’s risks and benefits. Media literacy programs can empower individuals to critically evaluate AI-generated content.

-Incentives for Ethical AI: Governments and industry bodies can offer incentives such as grants, tax benefits, or certifications for companies that adopt ethical AI practices.

-Research and Development in AI Ethics: Supporting interdisciplinary research on AI ethics and governance can help address emerging challenges. Collaborations between academia, industry, and policymakers are essential to bridge gaps between theory and practice.

-Reskilling Programs for the Workforce: To mitigate the economic disruptions caused by AI-driven automation, targeted reskilling initiatives should be implemented. These programs can prepare workers for new roles in AI oversight, data analysis, and ethical auditing.

# Conclusion

The generative AI revolution presents unparalleled opportunities and challenges for society. As Correa et al. (2023) argue, establishing consensus on AI governance is critical to harness its potential while mitigating risks. By adopting inclusive, transparent, and accountable practices, computing professionals can lead the way in shaping an equitable and sustainable AI-driven future. Implementing the recommendations outlined above will not only address legal, social, and ethical concerns but also reinforce trust in AI technologies and the professionals who develop them.

# References

-BCS (2023) BCS Code of Conduct. Available at: https://www.bcs.org/media/2211/bcs-code-of-conduct.pdf (Accessed: 28 January 2025).

-Buolamwini, J. and Gebru, T. (2018) ‘Gender Shades: Intersectional accuracy disparities in commercial gender classification’, Proceedings of the Conference on Fairness, Accountability, and Transparency, pp. 77-91.

-Corrêa, N.K., Galvão, C., Santos, J.W., Del Pino, C., Pinto, E.P., Barbosa, C., Massmann, D., Mambrini, R., Galvão, L., Terem, E. and de Oliveira, N., (2023). Worldwide AI ethics: A review of 200 guidelines and recommendations for AI governance. Patterns, 4(10).

-Deckard, J. (2023), What are ethics in AI. Available at: https://www.bcs.org/articles-opinion-and-research/what-are-ethics-in-ai/ (Accessed: 28 January 2025).

-European Commission (2021) Proposal for a Regulation laying down harmonized rules on Artificial Intelligence. Available at: https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX:52021PC0206 (Accessed: 28 January 2025).

-IEEE (2020) Ethically Aligned Design: A Vision for Prioritizing Human Well-being with Autonomous and Intelligent Systems. Available at: https://standards.ieee.org/industry-connections/ec/autonomous-systems/ (Accessed: 28 January 2025).

-Goodman, B. and Flaxman, S. (2017) ‘European Union regulations on algorithmic decision-making and a ‘right to explanation’’, AI Magazine, 38(3), pp. 50-57.

-Office of Science and Technology Policy (2022) Blueprint for an AI Bill of Rights. Available at: https://www.govinfo.gov/app/details/GOVPUB-PREX23-PURL-gpo193638 (Accessed: 28 January 2025).




