---
layout: post
title: Module 3 unit8 seminar post
subtitle: Summary
categories: Module 3 unit8 seminar post
tags: [Cyber security, Essex, Threat models]
---

# Part A

1- Goerlandt et al (2017) proposed several approaches for assessing the validity of Quantitative Risk Assessment (QRA) approaches. They suggested that validation could be achieved through various ways as per below:

- Comparing Results with Historical Data: One approach they proposed is to compare the results of the QRA with historical data of incidents or accidents to see if the predicted outcomes align with what actually occurred.

- Peer Review: They suggested involving experts in the field to review the QRA methodology and results to assess its validity. Peer review can provide valuable insights and critiques.

- Scenario Testing: Another method they suggested is scenario testing, where different scenarios are simulated using the QRA approach, and the outcomes are compared against each other and against real-world observations.

- Sensitivity Analysis: Sensitivity analysis involves testing the sensitivity of the QRA model to different input parameters or assumptions. By varying these parameters and observing the changes in the results, researchers can gain insights into the robustness of the model.

- Model Calibration: Calibration involves adjusting the model parameters to better match observed data. By calibrating the QRA model against historical data or real-world observations, researchers can improve its validity.

The authors noted that while all these methods are valuable, they emphasized that the most effective approach to validate QRA methods depends on the specific context and purpose of the assessment. They suggested that a combination of these approaches may provide the most comprehensive validation of QRA methods.

2- Hugo et al (2018) discussed several techniques from the field of Quantitative Risk (QR) analysis that they suggested could be applied to project management. They recommended the following techniques:

Monte Carlo Simulation: This method entails running multiple simulations using random input values to evaluate the range of potential outcomes for a project. It helps in understanding the probabilistic nature of project risks and uncertainties.

Decision Trees: Decision trees are graphical representations of decision problems that inckude probabilities and results at various decision points. They help in assessing different decision alternatives and their associated risks.

Sensitivity Analysis: Sensitivity analysis entails the assessment regarding how changes in certain variables or assumptions affect project outcomes. It helps in identifying the most critical factors influencing project risk and uncertainty.

Probability Impact Matrix: This matrix helps in prioritizing and evaluating project risks based on their probability of occurrence and potential effect on the project objectives.

Regarding recommendations to increase the use of QR analysis in projects, Hugo et al (2018) suggested the following:

Education and Training: Providing education and training to project managers and team members on QR analysis techniques can increase their awareness and understanding of these methods.

Integration into Project Management Processes: Integrating QR analysis into existing project management processes and frameworks can help in mainstreaming its use within organizations.

Use of Software Tools: Utilizing software tools that support QR analysis techniques can make the process more efficient and accessible to project teams.

Risk Culture: Fostering a culture that values risk management and encourages the use of QR analysis techniques can promote their adoption in projects.

Continuous Improvement: Encouraging an environment or culture of continuous improvement where lessons learned from QR analysis are documented and included into future projects can improve the effectiveness of risk management practices.

By implementing these recommendations, organizations can enhance their ability to manage risks effectively and improve project outcomes.

3- In their 2020 review, Çelikbilek & Tüysüz (2020) compared various Multi-Criteria Decision Methods (MCDMs) and assessed their relative accuracy and validity. They found that the Analytic Hierarchy Process (AHP) was considered the most accurate of the methods compared.

Regarding the failings of the general Technique for Order of Preference by Similarity to Ideal Solution (TOPSIS) approach, some shortcomings highlighted by the authors may include:

Sensitivity to Weighting Schemes: TOPSIS relies heavily on the determination of criteria weights, and the choice of weighting scheme can significantly impact the results. The method may not adequately account for uncertainties or variations in criteria importance.

Assumption of Linearity: TOPSIS assumes a linear relationship between criteria and alternatives, that might not always hold true in real-world decision-making scenarios where relationships could be nonlinear or complex.

Difficulty in Handling Subjectivity: While TOPSIS provides a systematic framework for decision-making, it may struggle to handle subjective preferences or qualitative factors effectively.

Lack of Robustness: The TOPSIS method may lack robustness in situations where there is ambiguity or inconsistency in decision criteria or where there are multiple conflicting objectives.

Overall, while TOPSIS is a popular and widely used MCDM technique, its effectiveness can be limited by these and other factors. Researchers and practitioners should carefully consider the specific characteristics of their decision-making problem and the underlying assumptions of the TOPSIS method before applying it.

# Part B

Unfortunately, it didnt work for me. I am getting run time error
subscript out of range, tried different scenarios but unfortunately same outcome

# References

Çelikbilek, Y. and Tüysüz, F. (2020) “An in-depth review of theory of the TOPSIS method: An experimental analysis,” Journal of Management Analytics, 7(2). Available at: https://doi.org/10.1080/23270012.2020.1748528.

  Eckstein, J. and Riedmueller, S.T. (2002) “YASAI: Yet Another Add-in for Teaching Elementary Monte Carlo Simulation in Excel,” INFORMS Transactions on Education, 2(2). Available at: https://doi.org/10.1287/ited.2.2.12.

  Goerlandt, F., Khakzad, N. and Reniers, G. (2017) “Validity and validation of safety-related quantitative risk analysis: A review,” Safety Science, 99. Available at: https://doi.org/10.1016/j.ssci.2016.08.023.

  Hugo, F.D., Pretorius, L. and Benade, S.J. (2018) “Some aspects of the use and usefulness of quantitative risk analysis tools in project management,” South African Journal of Industrial Engineering, 29(4). Available at: https://doi.org/10.7166/29-4-1821.

Olson, D.L., Wu, D., Olson, D.L. and Wu, D., (2020). Enterprise risk management in projects (pp. 165-177). Springer Berlin Heidelberg.


